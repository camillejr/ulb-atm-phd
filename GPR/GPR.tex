\documentclass[10pt,twocolumn]{article}
\usepackage{geometry}
\geometry{verbose,headsep=3cm,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.0cm,rmargin=2.0cm}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[font=small]{caption}
\usepackage{amsmath,amssymb,latexsym}
\usepackage{marvosym}
\usepackage{url}
\usepackage{lipsum}
\usepackage{bm}
\usepackage{float}
\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{epsf}
\usepackage{float}
\usepackage{mathpazo}
\usepackage{pifont}
\usepackage{wrapfig}
\usepackage{multicol}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{framed}
\usepackage[utf8]{inputenc}
% Document font:
\usepackage{charter}

\begin{document}

\twocolumn[{
\begin{@twocolumnfalse}

  \begin{center}
%\textcolor{lgray}
    \vskip-5em

    \hfill
    \fontsize{10}{10}\selectfont {\textit{Bruxelles, January 2019}}
    \vskip2ex
	\vspace{5ex}
    \fontsize{20}{10}\selectfont {Notes on Gaussian Process Regression}
      \vspace{1ex}
      
      \fontsize{16}{10}\selectfont {(with Python examples)}
  \noindent%
    
\vskip1ex

{\rule{\textwidth}{0.5pt}}

  \end{center}
  
    \fontsize{7}{10}\selectfont {This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.}

\vspace{6mm}

\end{@twocolumnfalse}
}]

%%% HEADER END -----------------------------------------------------------
% ------------------------------------------------------------------------

\vspace{10mm}

\setlength{\parindent}{0cm}

\fontsize{14}{10}\selectfont {Kamila Zdybał}

\vspace{2mm}

\fontsize{8}{10}\selectfont {\textit{Université libre de Bruxelles, kamila.zdybal@ulb.ac.be}}

\fontsize{8}{10}\selectfont {\textit{camillejr.github.io/science-docs, kamila.zdybal@gmail.com}}

\section*{Preface}

\,\,

This document is still in preparation. Please feel free to contact me with any suggestions, corrections or comments.

\section*{Keywords}

\textit{Gausssian Process Regression (GPR), regression, covariance}

\tableofcontents

\section{Introduction}









\section{Covariance matrix}

Let's think about a dot product between two vectors:

\begin{equation}
\text{dot}(x_i, x_j) = |x_i| |x_j| \text{cos}(\phi)
\end{equation}

It describes the amount of projection of vector $x_i$ onto $x_j$ (or vice versa) and can be useful when we need to know how much one vector points in the direction of the other. 

Now imagine that you have a data set $\mathbf{X}$ with $n$ vectors (features), and you would like to know what is the dot product of every possible pair drawn from these vectors. In other words, you would like to know how correlated are all vectors with each other. You can achieve this "global" dot product by multiplying:

\begin{equation}
\mathbf{S} = \mathbf{X}^T \mathbf{X} 
\end{equation}

the result $\mathbf{S}$ is called the \textit{covariance matrix}. Notice that every entry $(i,j)$ in this matrix is a dot product $\text{dot}(x_i, x_j)$ and it is:

\begin{equation}
\text{dot}(x_i, x_j) = \text{cov}(x_i, x_j) \,\,\, \text{for} \,\,\, i \neq j
\end{equation}

\begin{equation}
\text{dot}(x_i, x_j) = \text{var}(x_i, x_j) \,\,\, \text{for} \,\,\, i = j
\end{equation}

The covariance matrix is symmetric due to symmetry: $\text{dot}(x_i, x_j) = \text{dot}(x_j, x_i)$.

\section{Covariance kernels}

The \textit{covariance kernel} is essentialy a function that populates the covariance matrix. This makes our life easier, since first, this matrix might be huge and second, we can easily implement the underlying structure to the covariance.

The covariance kernel has to be designed such that there is symmetry: $K(x_i, x_j) = K(x_j, x_i)$.\footnote{In \cite{Scaife}, it has been said that the covariance can vary in different directions which made me wonder...}

\subsection{Examples}

Squared exponential kernel:

\begin{equation}
K(x_i, x_j) = h^2 \exp(\frac{- (x_i - x_j)^2}{\lambda^2})
\end{equation}




\section{Building your GPR in Python}











\thebibliography{}

\bibitem{Rasmussen} C. E. Rasmussen, C. Williams, \textit{Gaussian Process for Machine Learning}, 2006

\bibitem{GP_for_TM} S. Roberts, M. Osborne, M. Ebden, S. Reece, N. Gibson, S. Aigrain \textit{Gaussian Processes for Timeseries Modelling}, 2012

\bibitem{Scaife} A. Scaife, \textit{Machine Learning: Gaussian Process Modelling in Python}, an online lecture



 \label{bib:pope}


\end{document}
